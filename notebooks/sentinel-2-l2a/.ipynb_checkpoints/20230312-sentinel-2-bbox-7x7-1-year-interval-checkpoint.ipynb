{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "626a022d-5469-4e2c-aba7-c6b00be60b54",
   "metadata": {},
   "source": [
    "# Level 1: Rice Crop Discovery Tool Benchmark Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfd5ecb-92da-4356-860f-64cec7534b45",
   "metadata": {},
   "source": [
    "## Challenge Level 1 Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e854b5f4-ee16-40da-a6d1-81898cc52aae",
   "metadata": {},
   "source": [
    "<p align=\"justify\">Welcome to the EY Open Science Data Challenge 2023! This challenge consists of two levels – Level 1 and Level 2. This is the Level 1 challenge aimed at participants who are beginners or have intermediate skill sets in data science and programming. The goal of Level 1 is to predict the presence of rice crops at a given location using satellite data. By the time you complete this level, you will have developed a rice crop classification model, which can distinguish between rice and non-rice fields. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c6226-0341-48c1-82b6-3fb000064462",
   "metadata": {},
   "source": [
    "<b>Challenge Aim: </b><p align=\"justify\"> <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdd1b29",
   "metadata": {},
   "source": [
    "<p align=\"justify\">In this notebook, we will demonstrate a basic model workflow that can serve as a starting point for the challenge. The basic model has been built to predict rice crops against non-rice crops (which might include forest, other vegetation and water bodies) using features from the Sentinel-1 Radiometrically Terrain Corrected (RTC)  dataset as predictor variables. In this demonstration, we have used two features from the Sentinel-1 dataset, namely VV (Vertical polarization – Vertical polarization) and VH (Vertical polarization – Horizontal polarization) and trained a logistic regression model with these features. We have extracted the VV band and VH band data from the Sentinel-1 dataset for one day (21st March 2020), with an assumption that VV and VH values for this day are representative of VV and VH values for the entire year (2020) for a given location.\n",
    "\n",
    "Most of the functions presented in this notebook were adapted from the <a href=\"https://planetarycomputer.microsoft.com/dataset/sentinel-1-rtc#Example-Notebook\">Sentinel-1-RTC notebook</a> found in the Planetary Computer portal.</p>\n",
    "    \n",
    "<p align=\"justify\"> Please note that this notebook is just a starting point. We have made many assumptions in this notebook that you may think are not best for solving the challenge effectively. You are encouraged to modify these functions, rewrite them, or try an entirely new approach.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb152d6-21e5-46c6-931d-11e99e6a6798",
   "metadata": {},
   "source": [
    "## Load In Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093dca36-dae9-4b87-9026-7508740cd746",
   "metadata": {},
   "source": [
    "To run this demonstration notebook, you will need to have the following packages imported below installed. This may take some time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c546caac-b5a5-494f-95e8-19a01e117492",
   "metadata": {},
   "source": [
    "#### Note: Environment setup\n",
    "Running this notebook requires an API key.\n",
    "\n",
    "To use your API key locally, set the environment variable <i><b>PC_SDK_SUBSCRIPTION_KEY</i></b> or use <i><b>planetary_computer.settings.set_subscription_key(<YOUR API Key>)</i></b><br>\n",
    "See <a href=\"https://planetarycomputer.microsoft.com/docs/concepts/sas/#when-an-account-is-needed\">when an account is needed for more </a>, and <a href=\"https://planetarycomputer.microsoft.com/account/request\">request</a> an account if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a03723e-78ae-4150-ba22-e2e485b95cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import ipyleaflet\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Evaluation and Tuning\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "# Planetary Computer Tools\n",
    "import pystac\n",
    "import pystac_client\n",
    "import odc\n",
    "from pystac_client import Client\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "from odc.stac import stac_load\n",
    "import planetary_computer as pc\n",
    "pc.settings.set_subscription_key('cf5657d28bb2408ba8fd775642c2e1cb')\n",
    "\n",
    "# Others\n",
    "import requests\n",
    "import rich.table\n",
    "from itertools import cycle\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from datetime import datetime\n",
    "import os\n",
    "from glob import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c268cf6",
   "metadata": {},
   "source": [
    "## Response Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80dbf04",
   "metadata": {},
   "source": [
    "Before building the model, we need to load in the rice crop presence data. We have curated for you data from a certain region in Vietnam for the year 2020. The data consists of  geo locations (Latitude and Longitude) with a tag specifying if the crop present in each geo location is rice or not.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f1da678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude and Longitude</th>\n",
       "      <th>Class of Land</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10.323727047081501, 105.2516346045924)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10.322364360592521, 105.27843410554115)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10.321455902933202, 105.25254306225168)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10.324181275911162, 105.25118037576274)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10.324635504740822, 105.27389181724476)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>(10.013942985253381, 105.67361318732796)</td>\n",
       "      <td>Non Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>(10.01348875642372, 105.67361318732796)</td>\n",
       "      <td>Non Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>(10.013034527594062, 105.67361318732796)</td>\n",
       "      <td>Non Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>(10.012580298764401, 105.67361318732796)</td>\n",
       "      <td>Non Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>(10.012126069934741, 105.67361318732796)</td>\n",
       "      <td>Non Rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Latitude and Longitude Class of Land\n",
       "0     (10.323727047081501, 105.2516346045924)          Rice\n",
       "1    (10.322364360592521, 105.27843410554115)          Rice\n",
       "2    (10.321455902933202, 105.25254306225168)          Rice\n",
       "3    (10.324181275911162, 105.25118037576274)          Rice\n",
       "4    (10.324635504740822, 105.27389181724476)          Rice\n",
       "..                                        ...           ...\n",
       "595  (10.013942985253381, 105.67361318732796)      Non Rice\n",
       "596   (10.01348875642372, 105.67361318732796)      Non Rice\n",
       "597  (10.013034527594062, 105.67361318732796)      Non Rice\n",
       "598  (10.012580298764401, 105.67361318732796)      Non Rice\n",
       "599  (10.012126069934741, 105.67361318732796)      Non Rice\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_presence_data = pd.read_csv(\"../../data/Crop_Location_Data.csv\")\n",
    "crop_presence_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6812c-7137-4873-b4ed-2dcdd470209b",
   "metadata": {},
   "source": [
    "## Predictor Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1487a9dc-1308-4c05-a69a-ccfe60bc9100",
   "metadata": {},
   "source": [
    "<p align =\"justify\">Now that we have our crop location data, it is time to gather the predictor variables from the Sentinel-1 dataset. For a more in-depth look regarding the Sentinel-1 dataset and how to query it, see the Sentinel-1 <a href=\"https://challenge.ey.com/api/v1/storage/admin-files/6403146221623637-63ca8d537b1fe300146c79d0-Sentinel%201%20Phenology.ipynb/\"> supplementary \n",
    "notebook</a>.\n",
    "    \n",
    "\n",
    "<p align = \"justify\">Sentinel-1 radar data penetrates through the clouds, thus helping us to get the band values with minimal atmospheric attenuation. Band values such as VV and VH help us in distinguishing between the rice and non rice crops. Hence we are choosing VV and VH as predictor variables for this experiment. \n",
    "        \n",
    "<ul>\n",
    "<li>VV - gamma naught values of signal transmitted with vertical polarization and received with vertical polarization with radiometric terrain correction applied.\n",
    "\n",
    "<li>VH - gamma naught values of signal transmitted with vertical polarization and received with horizontal polarization with radiometric terrain correction applied.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04011667-99ae-4820-a635-d8d50f716fe3",
   "metadata": {},
   "source": [
    "<h4 style=\"color:rgb(195, 52, 235)\"><strong>Tip 1</strong></h4>\n",
    "<p align=\"justify\">Participants might explore other combinations of bands from the Sentinel-1 data. For example, you can use mathematical combinations of bands to generate various <a href=\"https://challenge.ey.com/api/v1/storage/admin-files/3868217534768359-63ca8dc8aea56e00146e3489-Comprehensive%20Guide%20-%20Satellite%20Data.docx\">vegetation indices </a> which can then be used as features in your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c85257f-4a48-49e8-8036-10e9a6b69894",
   "metadata": {},
   "source": [
    "### Accessing the Sentinel-1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5399737c-46bb-44b7-bda8-4253c827e66d",
   "metadata": {},
   "source": [
    "<p align = \"Justify\">To get the Sentinel-1 data, we write a function called <i><b>get_sentinel_data.</b></i> This function will fetch VV and VH band values for a particular location over the specified time window. In this example, we have extracted VV and VH values for a day (21st March 2020). </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f85d6d-6c72-438b-81f8-8aafb1265b0a",
   "metadata": {},
   "source": [
    "<h4 style=\"color:rgb(195, 52, 235)\"><strong>Tip 2</strong></h4>\n",
    "<p align=\"justify\"> Extract VV and VH band values for an entire year. Different land classes (e.g., agriculture, water, urban) will have different annual variability. This variability will be better than a single date for accurately identifying land classes. Please find below a demonstration of extracting data for a day (21st March 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e339a34-cfa7-4899-9165-63ca7c01bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentinel_data(latlong,time_slice,assets):\n",
    "    '''\n",
    "    Returns VV and VH values for a given latitude and longitude \n",
    "    Attributes:\n",
    "    latlong - A tuple with 2 elements - latitude and longitude\n",
    "    time_slice - Timeframe for which the VV and VH values have to be extracted\n",
    "    assets - A list of bands to be extracted\n",
    "    '''\n",
    "\n",
    "    latlong=latlong.replace('(','').replace(')','').replace(' ','').split(',')\n",
    "    bbox_of_interest = (float(latlong[1]) , float(latlong[0]), float(latlong[1]) , float(latlong[0]))\n",
    "    time_of_interest = time_slice\n",
    "\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "    )\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-1-rtc\"], bbox=bbox_of_interest, datetime=time_of_interest\n",
    "    )\n",
    "    items = list(search.get_all_items())\n",
    "    bands_of_interest = assests\n",
    "    data = stac_load(items, patch_url=pc.sign, bbox=bbox_of_interest)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab9734-6cdf-466f-87c3-8067b05b90ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4 style=\"color:rgb(195, 52, 235)\"><strong>Tip 3 </strong></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb9b25-0c41-4f55-aa33-082adeb34dbd",
   "metadata": {},
   "source": [
    "Explore the approach of building a bounding box (e.g., 5x5 pixels) around the given latitude and longitude positions and then extract the aggregated band values (e.g., average, median) to get normalized band values to build the model. Radar data has inherent variability at the pixel level due to variable scattering response from the target. This effect is called “speckle” and it is common to filter the data to smooth these variations. Try using a 3x3, 5x5 or 7x7 window around the specific latitude and longitude point to get improved results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac1029-3dae-40e1-ac72-0a837225969d",
   "metadata": {},
   "source": [
    "## Downloading the Sentinel-1 Data for Reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35183698-eaff-472b-a77a-8647a9120ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare the Folder\n",
    "# directory=\"../../data/train/sentinel-1-rtc/1-year-202201-202212/vh-vv-1x1\"\n",
    "# if not os.path.exists(directory):\n",
    "#     print(\"Creating %s\" % (directory))\n",
    "#     os.makedirs(directory)\n",
    "#     print(\"Done\")\n",
    "# else:\n",
    "#     print(\"%s already existed\" % (directory))\n",
    "\n",
    "# # Download the Data\n",
    "# time_slice = \"2022-01-01/2022-12-31\"\n",
    "# assests = ['vh','vv']\n",
    "# vh_vv = []\n",
    "# for coordinates in tqdm(crop_presence_data['Latitude and Longitude']):\n",
    "#     data = get_sentinel_data(coordinates,time_slice,assests)\n",
    "#     data.to_netcdf(os.path.join(directory, coordinates+\".nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c51cd6e-41e2-4df4-ae07-349be861f0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:28<00:00, 20.86it/s]\n"
     ]
    }
   ],
   "source": [
    "## Function call to extract VV,VH Values\n",
    "directory_sen_1_rtc = \"../../data/train/sentinel-1-rtc/1-year-202201-202212/vh-vv-5x5/\"\n",
    "directory_sen_2_l2a = \"../../data/train/sentinel-2-l2a/1-year-202201-202212/vh-vv-5x5/\"\n",
    "dim_sen_1_rtc = ['y', 'x', 'time']\n",
    "dim_sen_2_l2a = ['longitude', 'latitude', 'time']\n",
    "vh_vv = []\n",
    "\n",
    "for coordinates in tqdm(crop_presence_data['Latitude and Longitude']):\n",
    "    data_sen_1_rtc = xr.open_dataset(directory_sen_1_rtc + coordinates + \".nc\")\n",
    "    data_sen_2_l2a = xr.open_dataset(directory_sen_2_l2a + coordinates + \".nc\")\n",
    "    mean_sen_1_rtc = data_sen_1_rtc.mean(dim=dim_sen_1_rtc).compute()\n",
    "    median_sen_1_rtc = data_sen_1_rtc.median(dim=dim_sen_1_rtc).compute()\n",
    "\n",
    "    median_vh = median_sen_1_rtc[\"vh\"].astype(\"float\").values.tolist()\n",
    "    median_vv = median_sen_1_rtc[\"vv\"].astype(\"float\").values.tolist()\n",
    "    mean_vh = mean_sen_1_rtc[\"vh\"].astype(\"float\").values.tolist()\n",
    "    mean_vv = mean_sen_1_rtc[\"vv\"].astype(\"float\").values.tolist()\n",
    "    \n",
    "    mean_sen_2_l2a = data_sen_2_l2a.mean(dim=dim_sen_2_l2a).compute()\n",
    "    median_sen_2_l2a = data_sen_2_l2a.median(dim=dim_sen_2_l2a).compute()\n",
    "    \n",
    "    median_nir = median_sen_1_rtc[\"vh\"].astype(\"float\").values.tolist()\n",
    "    median_red = median_sen_1_rtc[\"vv\"].astype(\"float\").values.tolist()\n",
    "    median_swir = median_sen_1_rtc[\"vh\"].astype(\"float\").values.tolist()\n",
    "    median_blue = median_sen_1_rtc[\"vv\"].astype(\"float\").values.tolist()\n",
    "    median_red_edge = median_sen_1_rtc[\"vv\"].astype(\"float\").values.tolist()\n",
    "\n",
    "    mean_nir = mean_sen_1_rtc[\"vh\"].astype(\"float\").values.tolist()\n",
    "    mean_red = mean_sen_1_rtc[\"vv\"].astype(\"float\").values.tolist()\n",
    "    mean_swir = mean_sen_1_rtc[\"vh\"].astype(\"float\").values.tolist()\n",
    "    mean_blue = mean_sen_1_rtc[\"vv\"].astype(\"float\").values.tolist()\n",
    "    mean_red_edge = mean_sen_1_rtc[\"vv\"].astype(\"float\").values.tolist()\n",
    "    \n",
    "    mean_ndvi = (mean_sen_2_l2a[\"nir\"]-mean_sen_2_l2a[\"red\"])/((mean_sen_2_l2a[\"nir\"]+mean_sen_2_l2a[\"red\"]))\n",
    "    median_ndvi = (mean_sen_2_l2a[\"nir\"]-mean_sen_2_l2a[\"red\"])/((mean_sen_2_l2a[\"nir\"]+mean_sen_2_l2a[\"red\"]))\n",
    "    \n",
    "    mean_ndwi = (mean_sen_2_l2a[\"nir\"]-mean_sen_2_l2a[\"swir16\"])/((mean_sen_2_l2a[\"nir\"]+mean_sen_2_l2a[\"swir16\"]))\n",
    "    median_ndwi = (mean_sen_2_l2a[\"nir\"]-mean_sen_2_l2a[\"swir16\"])/((mean_sen_2_l2a[\"nir\"]+mean_sen_2_l2a[\"swir16\"]))\n",
    "    \n",
    "    mean_psri = (mean_sen_2_l2a[\"red\"]-mean_sen_2_l2a[\"blue\"])/mean_sen_2_l2a[\"rededge\"]\n",
    "    median_psri = (mean_sen_2_l2a[\"red\"]-mean_sen_2_l2a[\"blue\"])/mean_sen_2_l2a[\"rededge\"]\n",
    "\n",
    "    vh_vv.append((\n",
    "        median_vh, median_vv,\n",
    "        mean_vh, mean_vv,\n",
    "        mean_ndvi, median_ndvi,\n",
    "        mean_ndwi, median_ndwi,\n",
    "        mean_psri, median_psri,\n",
    "    ))\n",
    "    \n",
    "\n",
    "columns = [\n",
    "    \"median_vh\", \"median_vv\",\n",
    "    \"mean_vh\", \"mean_vv\",\n",
    "    \"mean_ndvi\", \"median_ndvi\",\n",
    "    \"mean_ndwi\", \"median_ndwi\",\n",
    "    \"mean_psri\", \"median_psri\",\n",
    "]\n",
    "vh_vv_data = pd.DataFrame(vh_vv, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa872546-7567-418c-af04-1d8b4fa5bd60",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Joining the predictor variables and response variables\n",
    "Now that we have extracted our predictor variables, we need to join them onto the response variable . We use the function <i><b>combine_two_datasets</b></i> to combine the predictor variables and response variables.The <i><b>concat</b></i> function from pandas comes in handy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96296d95-8290-4f26-80f9-9e221bfcfc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_two_datasets(dataset1,dataset2):\n",
    "    '''\n",
    "    Returns a  vertically concatenated dataset.\n",
    "    Attributes:\n",
    "    dataset1 - Dataset 1 to be combined \n",
    "    dataset2 - Dataset 2 to be combined\n",
    "    '''\n",
    "    data = pd.concat([dataset1,dataset2], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20fa2b5f-727b-4781-9ff4-cc70596cd3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude and Longitude</th>\n",
       "      <th>Class of Land</th>\n",
       "      <th>median_vh</th>\n",
       "      <th>median_vv</th>\n",
       "      <th>mean_vh</th>\n",
       "      <th>mean_vv</th>\n",
       "      <th>mean_ndvi</th>\n",
       "      <th>median_ndvi</th>\n",
       "      <th>mean_ndwi</th>\n",
       "      <th>median_ndwi</th>\n",
       "      <th>mean_psri</th>\n",
       "      <th>median_psri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10.323727047081501, 105.2516346045924)</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.021028</td>\n",
       "      <td>0.095252</td>\n",
       "      <td>0.025203</td>\n",
       "      <td>0.121393</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.15636488)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.15636488)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.24631406)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.24631406)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(-0.10363004)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(-0.10363004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10.322364360592521, 105.27843410554115)</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.022269</td>\n",
       "      <td>0.083356</td>\n",
       "      <td>0.026224</td>\n",
       "      <td>0.137162</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.16596259)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.16596259)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.23644028)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.23644028)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(-0.08745498)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(-0.08745498)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10.321455902933202, 105.25254306225168)</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.018949</td>\n",
       "      <td>0.074043</td>\n",
       "      <td>0.024335</td>\n",
       "      <td>0.115715</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.14337029)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.14337029)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.24033034)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.24033034)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(-0.09578392)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(-0.09578392)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10.324181275911162, 105.25118037576274)</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.020816</td>\n",
       "      <td>0.095378</td>\n",
       "      <td>0.023035</td>\n",
       "      <td>0.130664</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.16076104)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.16076104)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.24654035)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.24654035)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(-0.09084027)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(-0.09084027)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10.324635504740822, 105.27389181724476)</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.022629</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>0.028166</td>\n",
       "      <td>0.149396</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.1707887)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.1707887)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.23926032)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(0.23926032)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(-0.08707368)</td>\n",
       "      <td>&lt;xarray.DataArray ()&gt;\\narray(-0.08707368)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Latitude and Longitude Class of Land  median_vh  \\\n",
       "0   (10.323727047081501, 105.2516346045924)          Rice   0.021028   \n",
       "1  (10.322364360592521, 105.27843410554115)          Rice   0.022269   \n",
       "2  (10.321455902933202, 105.25254306225168)          Rice   0.018949   \n",
       "3  (10.324181275911162, 105.25118037576274)          Rice   0.020816   \n",
       "4  (10.324635504740822, 105.27389181724476)          Rice   0.022629   \n",
       "\n",
       "   median_vv   mean_vh   mean_vv                                 mean_ndvi  \\\n",
       "0   0.095252  0.025203  0.121393  <xarray.DataArray ()>\\narray(0.15636488)   \n",
       "1   0.083356  0.026224  0.137162  <xarray.DataArray ()>\\narray(0.16596259)   \n",
       "2   0.074043  0.024335  0.115715  <xarray.DataArray ()>\\narray(0.14337029)   \n",
       "3   0.095378  0.023035  0.130664  <xarray.DataArray ()>\\narray(0.16076104)   \n",
       "4   0.104919  0.028166  0.149396   <xarray.DataArray ()>\\narray(0.1707887)   \n",
       "\n",
       "                                median_ndvi  \\\n",
       "0  <xarray.DataArray ()>\\narray(0.15636488)   \n",
       "1  <xarray.DataArray ()>\\narray(0.16596259)   \n",
       "2  <xarray.DataArray ()>\\narray(0.14337029)   \n",
       "3  <xarray.DataArray ()>\\narray(0.16076104)   \n",
       "4   <xarray.DataArray ()>\\narray(0.1707887)   \n",
       "\n",
       "                                  mean_ndwi  \\\n",
       "0  <xarray.DataArray ()>\\narray(0.24631406)   \n",
       "1  <xarray.DataArray ()>\\narray(0.23644028)   \n",
       "2  <xarray.DataArray ()>\\narray(0.24033034)   \n",
       "3  <xarray.DataArray ()>\\narray(0.24654035)   \n",
       "4  <xarray.DataArray ()>\\narray(0.23926032)   \n",
       "\n",
       "                                median_ndwi  \\\n",
       "0  <xarray.DataArray ()>\\narray(0.24631406)   \n",
       "1  <xarray.DataArray ()>\\narray(0.23644028)   \n",
       "2  <xarray.DataArray ()>\\narray(0.24033034)   \n",
       "3  <xarray.DataArray ()>\\narray(0.24654035)   \n",
       "4  <xarray.DataArray ()>\\narray(0.23926032)   \n",
       "\n",
       "                                   mean_psri  \\\n",
       "0  <xarray.DataArray ()>\\narray(-0.10363004)   \n",
       "1  <xarray.DataArray ()>\\narray(-0.08745498)   \n",
       "2  <xarray.DataArray ()>\\narray(-0.09578392)   \n",
       "3  <xarray.DataArray ()>\\narray(-0.09084027)   \n",
       "4  <xarray.DataArray ()>\\narray(-0.08707368)   \n",
       "\n",
       "                                 median_psri  \n",
       "0  <xarray.DataArray ()>\\narray(-0.10363004)  \n",
       "1  <xarray.DataArray ()>\\narray(-0.08745498)  \n",
       "2  <xarray.DataArray ()>\\narray(-0.09578392)  \n",
       "3  <xarray.DataArray ()>\\narray(-0.09084027)  \n",
       "4  <xarray.DataArray ()>\\narray(-0.08707368)  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_data = combine_two_datasets(crop_presence_data,vh_vv_data)\n",
    "crop_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48faa0fb-0610-43ee-a4fa-f3453dc4feca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd4af7b5-41d1-4822-8d78-5e4bdc84b287",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a664ca55-dba1-440b-a4ef-2b6934c03929",
   "metadata": {},
   "source": [
    "<p align=\"justify\"> Now let us select the columns required for our model building exercise. We will consider only VV and VH for our model. It does not make sense to use latitude and longitude as predictor variables as they do not have any impact on presence of rice crop.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "536d53ad-2697-4283-8ceb-db94f93bad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_data = crop_data[[\n",
    "    'med_vh', 'med_vv',\n",
    "    'mean_vh', 'mean_vv',\n",
    "    # 'min_vh', 'min_vv',\n",
    "    # 'max_vh', 'max_vv',\n",
    "    # 'var_vh', 'var_vv',\n",
    "    # 'std_vh', 'std_vv',\n",
    "    'Class of Land',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b0956e5-9c4a-4728-8d6f-238e6f37d844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(crop_data['med_vh'], crop_data['med_vv'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2b5ff0e-11cd-4ca9-8dda-4d93f098c7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(crop_data['mean_vh'], crop_data['mean_vv'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca40658-8003-4195-b0d1-5efe29929ac9",
   "metadata": {},
   "source": [
    "### Train and Test Split "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46507f5-cfd1-43d8-8b05-aa09ce8016af",
   "metadata": {},
   "source": [
    "<p align=\"justify\">We will now split the data into 70% training data and 30% test data. Scikit-learn alias “sklearn” is a robust library for machine learning in Python. The scikit-learn library has a <i><b>model_selection</b></i> module in which there is a splitting function <i><b>train_test_split</b></i>. You can use the same.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "062ac03d-245d-49af-82d9-56d3ac581e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = crop_data.drop(columns=['Class of Land']).values\n",
    "y = crop_data ['Class of Land'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y,random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b031607b-9e71-46c8-beb1-3610ab59c56a",
   "metadata": {},
   "source": [
    "### Feature Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2140c8-3fed-49a4-b9c5-7378c12c5784",
   "metadata": {},
   "source": [
    "<p align=\"justify\"> Before initiating the model training we may have to execute different data pre-processing steps. Here we are demonstrating the scaling of VV and VH variable by using Standard Scaler.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859a23d-be08-4a7c-b27b-1a4afb03feb5",
   "metadata": {},
   "source": [
    "<p align = \"justify\">Feature Scaling is a data preprocessing step for numerical features. Many machine learning algorithms like Gradient descent methods, KNN algorithm, linear and logistic regression, etc. require data scaling to produce good results. Scikit learn provides functions that can be used to apply data scaling. Here we are using Standard Scaler.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a85328e-bef5-4b81-b7a0-443557387e0c",
   "metadata": {},
   "source": [
    "<h4 style=\"color:rgb(195, 52, 235)\"><strong>Tip 4 </strong></h4>\n",
    "<p align=\"justify\">Participants might explore other feature scaling techniques like Min Max Scaler, Max Absolute Scaling, Robust Scaling etc.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1506aede-aca0-4acc-a9b7-c7547dd9ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# mm = MinMaxScaler()\n",
    "# X_train = mm.fit_transform(X_train)\n",
    "# X_test = mm.transform(X_test)\n",
    "\n",
    "# rb = RobustScaler()\n",
    "# X_train = rb.fit_transform(X_train)\n",
    "# X_test = rb.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae3762-af09-4b0e-b3b9-7f07bedc688a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e6a772-732b-45fa-9872-14856e57b849",
   "metadata": {},
   "source": [
    "<p justify =\"align\">Now that we have the data in a format appropriate for machine learning, we can begin training a model. In this demonstration notebook, we have used a binary logistic regression model from the scikit-learn library. This library offers a wide range of other models, each with the capacity for extensive parameter tuning and customization capabilities.</p>\n",
    "\n",
    "<p justify =\"align\">Scikit-learn models require separation of predictor variables and the response variable. You have to store the predictor variables in array X and the response variable in the array Y. You must make sure not to include the response variable in array X. It also doesn't make sense to use latitude and longitude as predictor variables in such a confined area, so we drop those too.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "972a480e-ffc8-44dc-a350-fc05b77731dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LogisticRegression(random_state=42), \n",
    "    SVC(random_state=42),\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    BernoulliNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    AdaBoostClassifier(random_state=42)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9fa052-ddb3-4417-adec-60efceef983a",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd54a2a1-e10a-48e0-b8e0-bedf715363d1",
   "metadata": {},
   "source": [
    "Now that we have trained our model , all that is left is to evaluate it. For evaluation we will generate the classification report and will plot the confusion matrix. Scikit-learn provides many other metrics that can be used for evaluation. You can even write a code on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda3713-4e27-4f5c-994d-80b529021da6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### In-Sample Evaluation\n",
    "<p align=\"Jutisfy\"> We will be generating a classification report and a confusion matrix for the training data. It must be stressed that this is in-sample performance testing , which is the performance testing on the training dataset. These metrics are NOT truly indicative of the model's performance. You should wait to test the model performance on the test data before you feel confident about your model.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e7f93-f45b-404c-a5bc-9f956cb8bddf",
   "metadata": {},
   "source": [
    "In this section, we make predictions on the training set and store them in the <b><i>insample_ predictions</i></b> variable. A confusion matrix is generated to gauge the robustness of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3378f787-9051-4ecb-b678-a63a9d49942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance,names,model_type):\n",
    "\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + ' FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "387e0132-53c7-42c2-8878-9601e40cc14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_comparison(models, X, y, cv):\n",
    "    # Initiate a DataFrame for the averages and a list for all measures\n",
    "    cv_accuracies = pd.DataFrame({\n",
    "        \"model\": [],\n",
    "        \"accuracy\": [],\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": [],\n",
    "    })\n",
    "    \n",
    "    for model in models:\n",
    "        accuracy = cross_val_score(model, X, y, scoring='accuracy', cv=cv)\n",
    "        mean_accuracy = round(accuracy.mean(), 4)\n",
    "        \n",
    "        recall = cross_val_score(model, X, y, scoring='recall_weighted', cv=cv)\n",
    "        mean_recall = round(recall.mean(), 4)\n",
    "        \n",
    "        precision = cross_val_score(model, X, y, scoring='precision_weighted', cv=cv)\n",
    "        mean_precision = round(precision.mean(), 4)\n",
    "        \n",
    "        f1_score = cross_val_score(model, X, y, scoring='f1_weighted', cv=cv)\n",
    "        mean_f1_score = round(f1_score.mean(), 4)\n",
    "        \n",
    "        cv_accuracies.loc[len(cv_accuracies.index)] = [\n",
    "            str(model), \n",
    "            mean_accuracy, \n",
    "            mean_precision, \n",
    "            mean_recall, \n",
    "            mean_f1_score,\n",
    "        ]        \n",
    "    return cv_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c513dec8-f108-4936-bf46-343cbf341810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(random_state=42)</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.8525</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.8173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC(random_state=42)</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BernoulliNB()</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>0.8628</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>0.8243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostClassifier(random_state=42)</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         model  accuracy  precision  recall  \\\n",
       "0          LogisticRegression(random_state=42)    0.8214     0.8525  0.8214   \n",
       "1                         SVC(random_state=42)    0.9976     0.9977  0.9976   \n",
       "2      RandomForestClassifier(random_state=42)    0.9952     0.9953  0.9952   \n",
       "3  GradientBoostingClassifier(random_state=42)    0.9952     0.9953  0.9952   \n",
       "4                                BernoulliNB()    0.8286     0.8628  0.8286   \n",
       "5                       KNeighborsClassifier()    0.9976     0.9977  0.9976   \n",
       "6          AdaBoostClassifier(random_state=42)    0.9952     0.9953  0.9952   \n",
       "\n",
       "   f1_score  \n",
       "0    0.8173  \n",
       "1    0.9976  \n",
       "2    0.9952  \n",
       "3    0.9952  \n",
       "4    0.8243  \n",
       "5    0.9976  \n",
       "6    0.9952  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIME]: 5.8707\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_cv = cv_comparison(models, X_train, y_train, 5)\n",
    "display(df_cv)\n",
    "print(\"[TIME]: %.4f\" % (time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "116b1a93-66fd-48f3-9fbc-f2ba31670c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC(random_state=42)</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostClassifier(random_state=42)</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BernoulliNB()</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>0.8628</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>0.8243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(random_state=42)</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.8525</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.8173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         model  accuracy  precision  recall  \\\n",
       "1                         SVC(random_state=42)    0.9976     0.9977  0.9976   \n",
       "5                       KNeighborsClassifier()    0.9976     0.9977  0.9976   \n",
       "2      RandomForestClassifier(random_state=42)    0.9952     0.9953  0.9952   \n",
       "3  GradientBoostingClassifier(random_state=42)    0.9952     0.9953  0.9952   \n",
       "6          AdaBoostClassifier(random_state=42)    0.9952     0.9953  0.9952   \n",
       "4                                BernoulliNB()    0.8286     0.8628  0.8286   \n",
       "0          LogisticRegression(random_state=42)    0.8214     0.8525  0.8214   \n",
       "\n",
       "   f1_score  \n",
       "1    0.9976  \n",
       "5    0.9976  \n",
       "2    0.9952  \n",
       "3    0.9952  \n",
       "6    0.9952  \n",
       "4    0.8243  \n",
       "0    0.8173  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv.sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a26c98e7-02da-44da-8091-6e93ebb40103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Voting Classifier\n",
    "vt_model = VotingClassifier(estimators=[\n",
    "    ('gnb', models[3]), \n",
    "    ('rf', models[2]), \n",
    "    ('svc', models[1]), \n",
    "    ('knn', models[5]), \n",
    "    ('adb', models[6])], \n",
    "    voting='hard')\n",
    "vt_model = vt_model.fit(X_train, y_train)\n",
    "model = models[2].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8e9fe6c9-3a0b-4ef7-a168-1178c7547eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importance(model.feature_importances_, columns, \"RANDOM FOREST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a7a4196f-226e-4c52-8a64-bc00535bc97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "insample_predictions = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e131de89-a22d-4912-9f9b-6c7a12769c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insample Accuracy 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non Rice       1.00      1.00      1.00       210\n",
      "        Rice       1.00      1.00      1.00       210\n",
      "\n",
      "    accuracy                           1.00       420\n",
      "   macro avg       1.00      1.00      1.00       420\n",
      "weighted avg       1.00      1.00      1.00       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Insample Accuracy {0:.2f}%\".format(100*accuracy_score(insample_predictions,y_train)))\n",
    "print(classification_report(insample_predictions,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847aa72-37b8-498b-bd63-4130d1366b7e",
   "metadata": {},
   "source": [
    "<p> For plotting a confusion matrix we define the function <b><i>plot_confusion_matrix</i></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bb97e054-6e73-4d90-89e2-36ce094721f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(true_value,predicted_value,title,labels):\n",
    "    '''\n",
    "    Plots a confusion matrix.\n",
    "    Attributes:\n",
    "    true_value - The ground truth value for comparision.\n",
    "    predicted_value - The values predicted by the model.\n",
    "    title - Title of the plot.\n",
    "    labels - The x and y labels of the plot.\n",
    "    '''\n",
    "    cm = confusion_matrix(true_value,predicted_value)\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap='Blues');\n",
    "    ax.set_xlabel('Predicted labels');\n",
    "    ax.set_ylabel('True labels'); \n",
    "    ax.set_title(title); \n",
    "    ax.xaxis.set_ticklabels(labels); \n",
    "    ax.yaxis.set_ticklabels(labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "99c77326-b7d5-4dc4-8101-96bece8aceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_train,insample_predictions,\"Model Level 1: Logistic\\nRegression Model In-Sample Results\",['Rice', 'Non Rice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fd9f2d-1add-499a-b692-f616ec02871d",
   "metadata": {},
   "source": [
    "### Out-Sample Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9e1681-0cae-42c1-ad00-0ad3bb7eca71",
   "metadata": {},
   "source": [
    "When evaluating a machine learning model, it is essential to correctly and fairly evaluate the model's ability to generalize. This is because models have a tendency to overfit the dataset they are trained on. To estimate the out-of-sample performance, we will predict on the test data now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0d7324d1-35fd-463f-9734-f2ad1552ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "outsample_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4fdec320-a85c-49b9-8177-a65d5b85317a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 99.44%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non Rice       1.00      0.99      0.99        90\n",
      "        Rice       0.99      1.00      0.99        90\n",
      "\n",
      "    accuracy                           0.99       180\n",
      "   macro avg       0.99      0.99      0.99       180\n",
      "weighted avg       0.99      0.99      0.99       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy {0:.2f}%\".format(100*accuracy_score(outsample_predictions, y_test)))\n",
    "print(classification_report(y_test, outsample_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "da5ed827-f3b8-47a2-865c-61bd2cd9621c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, outsample_predictions,\"Model Level 1: Logistic\\nRegression Model Out-Sample Results\",['Rice', 'Non Rice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0bd4a4-5976-4a37-8f5b-fe46cf841e1f",
   "metadata": {},
   "source": [
    "From the above, we see that the model is able to achieve an F1 score of <b>0.57</b>. This is not a very good score, so your goal is to improve this score.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd805c-d58f-4840-b1dc-bbdf1630f201",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0c77b-e8c1-4375-b145-c2da6fe458fc",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ccbff7d0-10ae-4fb2-a50c-685368e8c9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gb_hyperparams = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_leaf': [1, 2, 4, 6],\n",
    "    'min_samples_split': [2, 4, 6, 8],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1a8718de-3698-4b8d-b7c3-dbd6dbb493a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.988 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=6, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=9, min_samples_leaf=6, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=9, min_samples_leaf=4, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=6, min_samples_split=2, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=6, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=2, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=2, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=2, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=2, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=0.988 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=1, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=6, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=6, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=6, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.988 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=6, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=6, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=6, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=6, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=200;, score=0.988 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=2, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=0.988 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.988 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=6, min_samples_split=2, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=6, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=6, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=9, min_samples_leaf=6, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=9, min_samples_leaf=6, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=9, min_samples_leaf=6, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=9, min_samples_leaf=6, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=9, min_samples_leaf=4, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=9, min_samples_leaf=4, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=9, min_samples_leaf=4, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=9, min_samples_leaf=4, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=1, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=1, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=1, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=1, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=0.988 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=6, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=6, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=4, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=4, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=4, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=4, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=2, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=2, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=2, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=2, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=6, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=6, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.988 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=4, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=2, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, min_samples_leaf=6, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=4, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.988 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=4, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=4, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "{'n_estimators': 200, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_depth': 5, 'learning_rate': 0.2}\n",
      "{'learning_rate': 0.001, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Create the model to be tuned\n",
    "gb_base = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Create the random search Random Forest\n",
    "gb_random = RandomizedSearchCV(\n",
    "    estimator = gb_base, \n",
    "    param_distributions = gb_hyperparams, \n",
    "    n_iter = 100, \n",
    "    cv = 5, \n",
    "    verbose=3,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "gb_grid = GridSearchCV(\n",
    "    estimator = gb_base, \n",
    "    param_grid = gb_hyperparams,\n",
    "    cv = 5, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# Fit the random search model\n",
    "gb_random.fit(X_train, y_train)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "# View the best parameters from the random search\n",
    "print(gb_random.best_params_)\n",
    "print(gb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b307328e-7d13-47b7-b079-94e3ababa912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9952380952380953\n",
      "0.9952380952380953\n"
     ]
    }
   ],
   "source": [
    "print(gb_random.best_score_)\n",
    "print(gb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c8781c20-4e26-4332-9f66-5bd9706b424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_best_model = gb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d58461-f84b-43e9-a6c7-6778068c0953",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "96de35d8-8d90-4d50-b678-c1141929e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "dfdf0af1-768b-4d0c-a2b8-14060d12eea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1400,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 90,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model to be tuned\n",
    "rf_base = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Create the random search Random Forest\n",
    "rf_random = RandomizedSearchCV(estimator = rf_base, param_distributions = random_grid, \n",
    "                               n_iter = 200, cv = 5, \n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# View the best parameters from the random search\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e665ece5-59d8-467b-bbaf-426586e3d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_model = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61473b3f-14bf-4752-a257-028d46d56b25",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "25abb085-d7ea-48e3-b2fc-d35628562a35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.690 total time=   0.0s\n",
      "[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END .........C=1, gamma=1, kernel=poly;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END .........C=1, gamma=1, kernel=poly;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=0.690 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.774 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.702 total time=   0.0s\n",
      "[CV 5/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.0001, gamma=1, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.0001, gamma=1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.0001, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.0001, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.0001, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.583 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.583 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.607 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.524 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.964 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.798 total time=   0.4s\n",
      "[CV 2/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.869 total time=   0.3s\n",
      "[CV 3/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.857 total time=   0.4s\n",
      "[CV 4/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.821 total time=   0.5s\n",
      "[CV 5/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.833 total time=   0.3s\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "[CV 1/5] END ..C=0.0001, gamma=1, kernel=linear;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.0001, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.0001, gamma=1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.0001, gamma=1, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.0001, gamma=1, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.0001, gamma=1, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.0001, gamma=1, kernel=poly;, score=0.679 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.0001, gamma=1, kernel=poly;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.0001, gamma=1, kernel=poly;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.0001, gamma=1, kernel=poly;, score=0.702 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.0001, gamma=1, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.0001, gamma=1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.0001, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.0001, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.0001, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .C=0.0001, gamma=1, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END .C=0.0001, gamma=1, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END .C=0.0001, gamma=1, kernel=sigmoid;, score=0.845 total time=   0.0s\n",
      "[CV 4/5] END .C=0.0001, gamma=1, kernel=sigmoid;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END .C=0.0001, gamma=1, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.1, kernel=linear;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.1, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.1, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.0001, gamma=0.1, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.0001, gamma=0.1, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.0001, gamma=0.1, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.0001, gamma=0.1, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.0001, gamma=0.1, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.0001, gamma=0.1, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.0001, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.0001, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.0001, gamma=0.1, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.0001, gamma=0.1, kernel=rbf;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.1, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.1, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.1, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.1, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.1, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.01, kernel=linear;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.01, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.01, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.01, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.01, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END .C=0.0001, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END .C=0.0001, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END .C=0.0001, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END .C=0.0001, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END .C=0.0001, gamma=0.01, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.0001, gamma=0.01, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.0001, gamma=0.01, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.0001, gamma=0.01, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.0001, gamma=0.01, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.0001, gamma=0.01, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.01, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.01, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.01, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.01, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.01, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.001, kernel=linear;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.001, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.001, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END .C=0.0001, gamma=0.001, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END .C=0.0001, gamma=0.001, kernel=rbf;, score=0.821 total time=   0.0s\n",
      "[CV 3/5] END .C=0.0001, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .C=0.0001, gamma=0.001, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END .C=0.0001, gamma=0.001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.0001, kernel=linear;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.0001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.0001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.0001, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.0001, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.0001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.0001, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.0001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.0001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.0001, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.0001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.0001, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.0001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.0001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.0001, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.0001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.001, gamma=1, kernel=linear;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.001, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.001, gamma=1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.001, gamma=1, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.001, gamma=1, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.001, gamma=1, kernel=poly;, score=0.679 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.001, gamma=1, kernel=poly;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.001, gamma=1, kernel=poly;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.001, gamma=1, kernel=poly;, score=0.702 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.001, gamma=1, kernel=poly;, score=0.762 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.001, gamma=1, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.001, gamma=1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.001, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.001, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.001, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.001, gamma=1, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.001, gamma=1, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.001, gamma=1, kernel=sigmoid;, score=0.845 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.001, gamma=1, kernel=sigmoid;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.001, gamma=1, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .C=0.001, gamma=0.1, kernel=linear;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END .C=0.001, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END .C=0.001, gamma=0.1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .C=0.001, gamma=0.1, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END .C=0.001, gamma=0.1, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.001, gamma=0.1, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.001, gamma=0.1, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.001, gamma=0.1, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.001, gamma=0.1, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.001, gamma=0.1, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.001, gamma=0.1, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.001, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.001, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.001, gamma=0.1, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.001, gamma=0.1, kernel=rbf;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, gamma=0.1, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.1, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.1, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.1, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.1, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, gamma=0.01, kernel=linear;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.01, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.01, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.01, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.01, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.001, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.001, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.001, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.001, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.001, gamma=0.01, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.001, gamma=0.01, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.001, gamma=0.01, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.001, gamma=0.01, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.001, gamma=0.01, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.001, gamma=0.01, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, gamma=0.01, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.01, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.01, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.01, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.01, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, gamma=0.001, kernel=linear;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.001, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.001, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END .C=0.001, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END .C=0.001, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END .C=0.001, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END .C=0.001, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END .C=0.001, gamma=0.001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.001, gamma=0.001, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.001, gamma=0.001, kernel=rbf;, score=0.821 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.001, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.001, gamma=0.001, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.001, gamma=0.001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, gamma=0.0001, kernel=linear;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.0001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.0001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.0001, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.0001, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.0001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END .C=0.001, gamma=0.0001, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END .C=0.001, gamma=0.0001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END .C=0.001, gamma=0.0001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .C=0.001, gamma=0.0001, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END .C=0.001, gamma=0.0001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, gamma=0.0001, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.0001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.0001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.0001, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.0001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.01, gamma=1, kernel=linear;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.01, gamma=1, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.01, gamma=1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.01, gamma=1, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.01, gamma=1, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.01, gamma=1, kernel=poly;, score=0.679 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.01, gamma=1, kernel=poly;, score=0.762 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.01, gamma=1, kernel=poly;, score=0.762 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.01, gamma=1, kernel=poly;, score=0.702 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.01, gamma=1, kernel=poly;, score=0.762 total time=   0.0s\n",
      "[CV 1/5] END .......C=0.01, gamma=1, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 2/5] END .......C=0.01, gamma=1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END .......C=0.01, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .......C=0.01, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=0.01, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.01, gamma=1, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.01, gamma=1, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.01, gamma=1, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.01, gamma=1, kernel=sigmoid;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.01, gamma=1, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.01, gamma=0.1, kernel=linear;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.01, gamma=0.1, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.01, gamma=0.1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.01, gamma=0.1, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.01, gamma=0.1, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.01, gamma=0.1, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.01, gamma=0.1, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.01, gamma=0.1, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.01, gamma=0.1, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.01, gamma=0.1, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.01, gamma=0.1, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.01, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.01, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.01, gamma=0.1, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.01, gamma=0.1, kernel=rbf;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END .C=0.01, gamma=0.1, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END .C=0.01, gamma=0.1, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END .C=0.01, gamma=0.1, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .C=0.01, gamma=0.1, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END .C=0.01, gamma=0.1, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .C=0.01, gamma=0.01, kernel=linear;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END .C=0.01, gamma=0.01, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END .C=0.01, gamma=0.01, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .C=0.01, gamma=0.01, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END .C=0.01, gamma=0.01, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.01, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.01, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.01, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.01, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.01, gamma=0.01, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.01, gamma=0.01, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.01, gamma=0.01, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.01, gamma=0.01, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.01, gamma=0.01, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.01, gamma=0.01, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, gamma=0.01, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, gamma=0.01, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, gamma=0.01, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, gamma=0.01, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=0.01, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, gamma=0.001, kernel=linear;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, gamma=0.001, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, gamma=0.001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, gamma=0.001, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=0.001, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.01, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.01, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.01, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.01, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.01, gamma=0.001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.01, gamma=0.001, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.01, gamma=0.001, kernel=rbf;, score=0.821 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.01, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.01, gamma=0.001, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.01, gamma=0.001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, gamma=0.0001, kernel=linear;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, gamma=0.0001, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, gamma=0.0001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, gamma=0.0001, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=0.0001, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END .C=0.01, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END .C=0.01, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END .C=0.01, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END .C=0.01, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END .C=0.01, gamma=0.0001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.01, gamma=0.0001, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.01, gamma=0.0001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.01, gamma=0.0001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.01, gamma=0.0001, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.01, gamma=0.0001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.690 total time=   0.0s\n",
      "[CV 2/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.762 total time=   0.0s\n",
      "[CV 4/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.702 total time=   0.0s\n",
      "[CV 5/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.738 total time=   0.0s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.774 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.738 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.679 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.702 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.964 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.821 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END .........C=1, gamma=1, kernel=poly;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END .........C=1, gamma=1, kernel=poly;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=0.690 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.595 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.607 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.619 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.548 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.690 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.679 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.702 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.762 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ........C=10, gamma=1, kernel=poly;, score=0.869 total time=   0.2s\n",
      "[CV 2/5] END ........C=10, gamma=1, kernel=poly;, score=0.881 total time=   0.2s\n",
      "[CV 3/5] END ........C=10, gamma=1, kernel=poly;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END ........C=10, gamma=1, kernel=poly;, score=0.750 total time=   0.2s\n",
      "[CV 5/5] END ........C=10, gamma=1, kernel=poly;, score=0.810 total time=   0.2s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.583 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.583 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.607 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.524 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.679 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.762 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.762 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.702 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.762 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.774 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.702 total time=   0.0s\n",
      "[CV 5/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.964 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=0.821 total time=   0.1s\n",
      "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .......C=100, gamma=1, kernel=poly;, score=0.893 total time=   1.3s\n",
      "[CV 2/5] END .......C=100, gamma=1, kernel=poly;, score=0.929 total time=   1.2s\n",
      "[CV 3/5] END .......C=100, gamma=1, kernel=poly;, score=0.917 total time=   1.3s\n",
      "[CV 4/5] END .......C=100, gamma=1, kernel=poly;, score=0.952 total time=   1.3s\n",
      "[CV 5/5] END .......C=100, gamma=1, kernel=poly;, score=0.869 total time=   1.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.583 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.583 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.607 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.524 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.976 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.821 total time=   0.1s\n",
      "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.690 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.762 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.702 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.738 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.476 total time=   0.0s\n",
      "[CV 2/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.548 total time=   0.0s\n",
      "[CV 3/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.607 total time=   0.0s\n",
      "[CV 4/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.476 total time=   0.0s\n",
      "[CV 5/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.512 total time=   0.0s\n",
      "[CV 1/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.821 total time=   0.1s\n",
      "[CV 5/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.679 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.702 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .C=100, gamma=0.001, kernel=linear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END .C=100, gamma=0.001, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END .C=100, gamma=0.001, kernel=linear;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END .C=100, gamma=0.001, kernel=linear;, score=0.821 total time=   0.1s\n",
      "[CV 5/5] END .C=100, gamma=0.001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=0.0001, kernel=linear;, score=0.798 total time=   0.1s\n",
      "[CV 2/5] END C=100, gamma=0.0001, kernel=linear;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=0.0001, kernel=linear;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END C=100, gamma=0.0001, kernel=linear;, score=0.821 total time=   0.1s\n",
      "[CV 5/5] END C=100, gamma=0.0001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END ....C=1000, gamma=1, kernel=linear;, score=0.798 total time=   0.4s\n",
      "[CV 2/5] END ....C=1000, gamma=1, kernel=linear;, score=0.869 total time=   0.3s\n",
      "[CV 3/5] END ....C=1000, gamma=1, kernel=linear;, score=0.857 total time=   0.4s\n",
      "[CV 4/5] END ....C=1000, gamma=1, kernel=linear;, score=0.821 total time=   0.5s\n",
      "[CV 5/5] END ....C=1000, gamma=1, kernel=linear;, score=0.833 total time=   0.4s\n",
      "[CV 1/5] END ......C=1000, gamma=1, kernel=poly;, score=0.940 total time=   8.5s\n",
      "[CV 2/5] END ......C=1000, gamma=1, kernel=poly;, score=0.940 total time=   7.7s\n",
      "[CV 3/5] END ......C=1000, gamma=1, kernel=poly;, score=0.929 total time=   9.9s\n",
      "[CV 4/5] END ......C=1000, gamma=1, kernel=poly;, score=0.952 total time=   9.0s\n",
      "[CV 5/5] END ......C=1000, gamma=1, kernel=poly;, score=0.917 total time=   8.1s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.583 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.583 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.607 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.524 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.964 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.798 total time=   0.4s\n",
      "[CV 2/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.869 total time=   0.3s\n",
      "[CV 3/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.857 total time=   0.4s\n",
      "[CV 4/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.821 total time=   0.5s\n",
      "[CV 5/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.833 total time=   0.4s\n",
      "[CV 1/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.690 total time=   0.0s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.452 total time=   0.0s\n",
      "[CV 2/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.560 total time=   0.0s\n",
      "[CV 4/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.440 total time=   0.0s\n",
      "[CV 5/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.488 total time=   0.0s\n",
      "[CV 1/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.798 total time=   0.4s\n",
      "[CV 2/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.869 total time=   0.3s\n",
      "[CV 3/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.857 total time=   0.4s\n",
      "[CV 4/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.821 total time=   0.5s\n",
      "[CV 5/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.833 total time=   0.4s\n",
      "[CV 1/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.679 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.702 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.762 total time=   0.0s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.726 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.738 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.762 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.001, kernel=linear;, score=0.798 total time=   0.4s\n",
      "[CV 2/5] END C=1000, gamma=0.001, kernel=linear;, score=0.869 total time=   0.3s\n",
      "[CV 3/5] END C=1000, gamma=0.001, kernel=linear;, score=0.857 total time=   0.4s\n",
      "[CV 4/5] END C=1000, gamma=0.001, kernel=linear;, score=0.821 total time=   0.5s\n",
      "[CV 5/5] END C=1000, gamma=0.001, kernel=linear;, score=0.833 total time=   0.3s\n",
      "[CV 1/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.798 total time=   0.4s\n",
      "[CV 2/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.869 total time=   0.3s\n",
      "[CV 3/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.857 total time=   0.4s\n",
      "[CV 4/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.821 total time=   0.5s\n",
      "[CV 5/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.833 total time=   0.3s\n",
      "[CV 1/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "{'kernel': 'rbf', 'gamma': 1, 'C': 100}\n",
      "{'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['linear', 'poly', 'rbf', 'sigmoid']} \n",
    "  \n",
    "\n",
    "\n",
    "# Create the model to be tuned\n",
    "svc_base = SVC(random_state=42)\n",
    "\n",
    "svc_random = RandomizedSearchCV(svc_base, param_distributions=param_grid, verbose = 3)\n",
    "svc_grid = GridSearchCV(svc_base, param_grid=param_grid, verbose = 3)\n",
    "\n",
    "# Fit the random search model\n",
    "svc_random.fit(X_train, y_train)\n",
    "svc_grid.fit(X_train, y_train)\n",
    "\n",
    "# View the best parameters from the random search\n",
    "print(svc_random.best_params_)\n",
    "print(svc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f26cf311-9310-455b-9c85-d9552437aa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9976190476190476\n",
      "0.9976190476190476\n"
     ]
    }
   ],
   "source": [
    "print(svc_random.best_score_)\n",
    "print(svc_grid.best_score_)\n",
    "svc_best_model = svc_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a58516-79d9-48f0-bb50-34cc0ed65a43",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "97c072da-435d-4fb5-9cd2-369b8b7c2abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=6, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=50;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=6, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=6, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=6, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=6, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=0.988 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=6, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=6, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=4, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, min_samples_leaf=4, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=5, min_samples_leaf=6, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=2, min_samples_split=8, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, min_samples_leaf=1, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, min_samples_leaf=4, min_samples_split=4, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=6, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=6, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=7, min_samples_leaf=6, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.988 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=15, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=1, min_samples_split=8, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=4, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=4, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=7, min_samples_leaf=4, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, min_samples_leaf=6, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=3, min_samples_leaf=2, min_samples_split=6, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=6, min_samples_split=6, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=13, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=11, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=11, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=13, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=15, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=15, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=15, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=15, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=13, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=15, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "{'weights': 'uniform', 'n_neighbors': 15, 'metric': 'euclidean'}\n",
      "{'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = { 'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "# Create the model to be tuned\n",
    "knn_base = KNeighborsClassifier()\n",
    "\n",
    "knn_random = RandomizedSearchCV(knn_base, param_distributions=param_grid, verbose = 3, n_jobs = -1)\n",
    "knn_grid = GridSearchCV(knn_base, param_grid=param_grid, verbose = 3, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "knn_random.fit(X_train, y_train)\n",
    "knn_grid.fit(X_train, y_train)\n",
    "\n",
    "# View the best parameters from the random search\n",
    "print(knn_random.best_params_)\n",
    "print(knn_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7de2a5c5-be0f-4381-ab95-2f37202cbb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9976190476190476\n",
      "0.9976190476190476\n"
     ]
    }
   ],
   "source": [
    "print(knn_random.best_score_)\n",
    "print(knn_grid.best_score_)\n",
    "knn_best_model = knn_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7ac76-6097-48a4-9ab5-89eb85557b9e",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f7255603-8227-43cb-a266-6d3b6e2438ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=0.988 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=9, min_samples_leaf=2, min_samples_split=6, n_estimators=200;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=11, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=15, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=13, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=15, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=15, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=15, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=1.0, n_estimators=300;, score=1.000 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=400;, score=0.988 total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.001, n_estimators=400;, score=0.988 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.001, n_estimators=400;, score=1.000 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=1.0, n_estimators=500;, score=0.988 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.001, n_estimators=300;, score=1.000 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=1.0, n_estimators=400;, score=1.000 total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=50;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, n_estimators=200;, score=0.988 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=500;, score=0.988 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=100;, score=0.988 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.001, n_estimators=50;, score=0.988 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.001, n_estimators=100;, score=0.988 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.001, n_estimators=150;, score=1.000 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.001, n_estimators=150;, score=0.988 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.001, n_estimators=300;, score=0.988 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.001, n_estimators=300;, score=1.000 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.001, n_estimators=400;, score=0.988 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.001, n_estimators=400;, score=1.000 total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=50;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=100;, score=0.988 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=200;, score=0.988 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=200;, score=1.000 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=300;, score=1.000 total time=   0.6s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=13, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=11, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=11, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=15, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=15, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=15, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=15, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=15, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=11, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=1.0, n_estimators=300;, score=0.988 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=1.0, n_estimators=300;, score=1.000 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=400;, score=0.988 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.001, n_estimators=400;, score=1.000 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=1.0, n_estimators=500;, score=1.000 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.001, n_estimators=300;, score=0.988 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.001, n_estimators=300;, score=0.988 total time=   0.6s\n",
      "[CV 3/5] END learning_rate=1.0, n_estimators=400;, score=1.000 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.001, n_estimators=200;, score=1.000 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=500;, score=1.000 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=500;, score=1.000 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.001, n_estimators=50;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.001, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.001, n_estimators=150;, score=0.988 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.001, n_estimators=150;, score=1.000 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.001, n_estimators=200;, score=0.988 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.001, n_estimators=200;, score=1.000 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.001, n_estimators=400;, score=1.000 total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.001, n_estimators=400;, score=1.000 total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.001, n_estimators=500;, score=1.000 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=50;, score=0.988 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=100;, score=0.988 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=150;, score=0.988 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=150;, score=1.000 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=300;, score=1.000 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=300;, score=0.988 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=400;, score=1.000 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=500;, score=0.988 total time=   1.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=13, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=11, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=15, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=13, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=15, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=1.0, n_estimators=300;, score=1.000 total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=400;, score=1.000 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=400;, score=1.000 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=1.0, n_estimators=500;, score=0.988 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=1.0, n_estimators=500;, score=1.000 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.001, n_estimators=300;, score=1.000 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=1.0, n_estimators=400;, score=0.988 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=50;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.001, n_estimators=200;, score=1.000 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.001, n_estimators=200;, score=1.000 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=500;, score=0.988 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=100;, score=0.988 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.001, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.001, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.001, n_estimators=150;, score=1.000 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.001, n_estimators=200;, score=0.988 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.001, n_estimators=300;, score=1.000 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.001, n_estimators=300;, score=0.988 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.001, n_estimators=500;, score=0.988 total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.001, n_estimators=500;, score=1.000 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=150;, score=0.988 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=200;, score=1.000 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=200;, score=0.988 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=300;, score=1.000 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=400;, score=0.988 total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=500;, score=1.000 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=50;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=100;, score=0.988 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=150;, score=1.000 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=150;, score=1.000 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=200;, score=0.988 total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=300;, score=1.000 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=400;, score=0.988 total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=500;, score=1.000 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=1.0, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=1.0, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=1.0, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=1.0, n_estimators=150;, score=0.988 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=1.0, n_estimators=150;, score=0.988 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=1.0, n_estimators=200;, score=1.000 total time=   0.4s\n",
      "{'n_estimators': 300, 'learning_rate': 1.0}\n",
      "{'learning_rate': 0.001, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "    'n_estimators' : [50, 100, 150, 200, 300, 400, 500], \n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 1.0],\n",
    "}\n",
    "\n",
    "# Create the model to be tuned\n",
    "adb_base = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "adb_random = RandomizedSearchCV(adb_base, param_distributions=param_grid, verbose = 3, n_jobs = -1)\n",
    "adb_grid = GridSearchCV(adb_base, param_grid=param_grid, verbose = 3, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "adb_random.fit(X_train, y_train)\n",
    "adb_grid.fit(X_train, y_train)\n",
    "\n",
    "# View the best parameters from the random search\n",
    "print(adb_random.best_params_)\n",
    "print(adb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a432435d-bd93-49f1-af0b-56317f10a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_best_model = adb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629f3f5-5a51-45d7-9c68-75b969101405",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c178f-1113-4456-b1c6-3188273bc1f3",
   "metadata": {},
   "source": [
    "Once you are happy with your model, you can make a submission. To make a submission, you will need to use your model to make predictions about the presence of rice crops for a set of test coordinates we have provided in the <a href=\"https://challenge.ey.com/api/v1/storage/admin-files/6847912254281276-63ca8b5ab12e510013520e2b-challenge_1_submission_template.csv\"><b>\"challenge_1_submission_template.csv\"</b></a> file and upload the file onto the challenge platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c1fc4682-5a87-4ccb-9b4d-877221e397e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude and Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10.18019073690894, 105.32022315786804)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10.561107033461816, 105.12772097986661)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10.623790611954897, 105.13771401411867)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10.583364246115156, 105.23946127195805)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10.20744446668854, 105.26844107128906)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>(10.308283266873062, 105.50872812216863)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>(10.582910017285496, 105.23991550078767)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>(10.581547330796518, 105.23991550078767)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>(10.629241357910818, 105.15315779432643)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>(10.574733898351617, 105.10410108072531)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Latitude and Longitude  target\n",
       "0     (10.18019073690894, 105.32022315786804)     NaN\n",
       "1    (10.561107033461816, 105.12772097986661)     NaN\n",
       "2    (10.623790611954897, 105.13771401411867)     NaN\n",
       "3    (10.583364246115156, 105.23946127195805)     NaN\n",
       "4     (10.20744446668854, 105.26844107128906)     NaN\n",
       "..                                        ...     ...\n",
       "245  (10.308283266873062, 105.50872812216863)     NaN\n",
       "246  (10.582910017285496, 105.23991550078767)     NaN\n",
       "247  (10.581547330796518, 105.23991550078767)     NaN\n",
       "248  (10.629241357910818, 105.15315779432643)     NaN\n",
       "249  (10.574733898351617, 105.10410108072531)     NaN\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the coordinates for the submission\n",
    "test_file = pd.read_csv('../../data/challenge_1_submission_template.csv')\n",
    "test_file = test_file.rename(columns={\"id\": \"Latitude and Longitude\"})\n",
    "test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ad15ddd0-148f-4d0e-aba1-243391f7ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Prepare the Folder\n",
    "# # directory=\"../data/test/sentinel-1-rtc/1-year-202111-202211/vh-vv-1x1\"\n",
    "# directory = \"../../data/test/sentinel-1-rtc/1-year-202201-202212/vh-vv-5x5/\"\n",
    "\n",
    "# if not os.path.exists(directory):\n",
    "#     print(\"Creating %s\" % (directory))\n",
    "#     os.makedirs(directory)\n",
    "#     print(\"Done\")\n",
    "# else:\n",
    "#     print(\"%s already existed\" % (directory))\n",
    "\n",
    "# # Download the Data\n",
    "# time_slice = \"2021-01-01/2022-12-31\"\n",
    "# assests = ['vh','vv']\n",
    "# vh_vv = []\n",
    "# for coordinates in tqdm(test_file['Latitude and Longitude']):\n",
    "#     data = get_sentinel_data(coordinates,time_slice,assests)\n",
    "#     data.to_netcdf(os.path.join(directory, coordinates+\".nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c0c5e29a-3bfa-4f5e-ac00-ffbf6b18033e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 81.72it/s]\n"
     ]
    }
   ],
   "source": [
    "## Function call to extract VV,VH Values\n",
    "directory = \"../../data/test/sentinel-1-rtc/1-year-202201-202212/vh-vv-5x5/\"\n",
    "assests = ['vh','vv']\n",
    "vh_vv = []\n",
    "c = 0\n",
    "\n",
    "for coordinates in tqdm(test_file['Latitude and Longitude']):\n",
    "    data = xr.open_dataset(directory + coordinates + \".nc\")\n",
    "    median = data.median(dim=['y', 'x', 'time']).compute()\n",
    "    mean = data.mean(dim=['y', 'x', 'time']).compute()\n",
    "    minn = data.min(dim=['y', 'x', 'time']).compute()\n",
    "    maxx = data.max(dim=['y', 'x', 'time']).compute()\n",
    "    varr = data.var(dim=['y', 'x', 'time']).compute()\n",
    "    std = data.std(dim=['y', 'x', 'time']).compute()\n",
    "    med_vh = median[\"vh\"].astype(\"float\").values.tolist()\n",
    "    med_vv = median[\"vv\"].astype(\"float\").values.tolist()\n",
    "    mean_vh = mean[\"vh\"].astype(\"float\").values.tolist()\n",
    "    mean_vv = mean[\"vv\"].astype(\"float\").values.tolist()\n",
    "    min_vh = minn[\"vh\"].astype(\"float\").values.tolist()\n",
    "    min_vv = minn[\"vv\"].astype(\"float\").values.tolist()\n",
    "    max_vh = maxx[\"vh\"].astype(\"float\").values.tolist()\n",
    "    max_vv = maxx[\"vv\"].astype(\"float\").values.tolist()\n",
    "    var_vh = varr[\"vh\"].astype(\"float\").values.tolist()\n",
    "    var_vv = varr[\"vv\"].astype(\"float\").values.tolist()\n",
    "    std_vh = std[\"vh\"].astype(\"float\").values.tolist()\n",
    "    std_vv = std[\"vv\"].astype(\"float\").values.tolist()\n",
    "    vh_vv.append((\n",
    "        med_vh, med_vv,\n",
    "        mean_vh, mean_vv,\n",
    "        # min_vh, min_vv,\n",
    "        # max_vh, max_vv,\n",
    "        # var_vh, var_vv,\n",
    "        # std_vh, std_vv\n",
    "    ))\n",
    "    \n",
    "submission_vh_vv_data = pd.DataFrame(vh_vv,columns =[\n",
    "    'med_vh', 'med_vv',\n",
    "    'mean_vh', 'mean_vv',\n",
    "    # 'min_vh', 'min_vv',\n",
    "    # 'max_vh', 'max_vv',\n",
    "    # 'var_vh', 'var_vv',\n",
    "    # 'std_vh', 'std_vv'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2cb45aca-974a-41e1-a522-36ca202d9af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=0.01, n_estimators=500;, score=1.000 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=150;, score=0.988 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=200;, score=1.000 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=300;, score=1.000 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=400;, score=0.988 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=400;, score=1.000 total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=500;, score=0.988 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=1.0, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=1.0, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=1.0, n_estimators=150;, score=1.000 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=1.0, n_estimators=200;, score=0.988 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=1.0, n_estimators=200;, score=1.000 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=1.0, n_estimators=300;, score=0.988 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=1.0, n_estimators=400;, score=1.000 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=1.0, n_estimators=500;, score=1.000 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=400;, score=1.000 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=500;, score=1.000 total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=50;, score=0.988 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=100;, score=0.988 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=150;, score=0.988 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=200;, score=0.988 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=200;, score=1.000 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=300;, score=0.988 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=400;, score=1.000 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=500;, score=0.988 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=500;, score=1.000 total time=   1.0s\n",
      "[CV 2/5] END learning_rate=1.0, n_estimators=200;, score=1.000 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=1.0, n_estimators=300;, score=0.988 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=1.0, n_estimators=300;, score=1.000 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=1.0, n_estimators=400;, score=0.988 total time=   0.8s\n",
      "[CV 3/5] END learning_rate=1.0, n_estimators=500;, score=1.000 total time=   1.0s\n",
      "[CV 2/5] END learning_rate=1.0, n_estimators=300;, score=1.000 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=1.0, n_estimators=400;, score=0.988 total time=   0.7s\n",
      "[CV 5/5] END learning_rate=1.0, n_estimators=400;, score=1.000 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=1.0, n_estimators=500;, score=0.988 total time=   0.9s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=11, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=11, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=11, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=13, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=13, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=13, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=15, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=15, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=15, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=1.0, n_estimators=300;, score=0.988 total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=400;, score=1.000 total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.001, n_estimators=400;, score=1.000 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.001, n_estimators=400;, score=0.988 total time=   0.7s\n",
      "[CV 3/5] END learning_rate=1.0, n_estimators=500;, score=1.000 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.001, n_estimators=300;, score=1.000 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=1.0, n_estimators=400;, score=0.988 total time=   0.7s\n",
      "[CV 5/5] END learning_rate=1.0, n_estimators=400;, score=1.000 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.001, n_estimators=200;, score=0.988 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=500;, score=1.000 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.001, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.001, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.001, n_estimators=100;, score=0.988 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.001, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.001, n_estimators=200;, score=1.000 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.001, n_estimators=200;, score=1.000 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.001, n_estimators=300;, score=1.000 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.001, n_estimators=400;, score=0.988 total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.001, n_estimators=500;, score=1.000 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.001, n_estimators=500;, score=0.988 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=150;, score=1.000 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=150;, score=1.000 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=200;, score=1.000 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=300;, score=0.988 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=400;, score=0.988 total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=400;, score=1.000 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=500;, score=0.988 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=150;, score=1.000 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=200;, score=1.000 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=300;, score=0.988 total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=300;, score=1.000 total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=400;, score=1.000 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=500;, score=1.000 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=1.0, n_estimators=50;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=1.0, n_estimators=50;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=1.0, n_estimators=50;, score=0.988 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=1.0, n_estimators=100;, score=0.988 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=1.0, n_estimators=100;, score=0.988 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=1.0, n_estimators=150;, score=1.000 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=1.0, n_estimators=150;, score=1.000 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=1.0, n_estimators=200;, score=0.988 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=1.0, n_estimators=300;, score=1.000 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=1.0, n_estimators=400;, score=1.000 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=1.0, n_estimators=500;, score=0.988 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=1.0, n_estimators=500;, score=1.000 total time=   0.9s\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling \n",
    "submission_vh_vv_data = submission_vh_vv_data.values\n",
    "transformed_submission_data = sc.transform(submission_vh_vv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ecc34e3a-bfc1-49a0-94bb-ee1e540abe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions\n",
    "# Create Voting Classifier\n",
    "vt_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('gnb', GradientBoostingClassifier(\n",
    "            learning_rate = 0.001, \n",
    "            max_depth = 3, \n",
    "            min_samples_leaf = 1, \n",
    "            min_samples_split = 2, \n",
    "            n_estimators = 50)), \n",
    "        ('rf', RandomForestClassifier(\n",
    "            n_estimators = 1400,\n",
    "            min_samples_split = 5,\n",
    "            min_samples_leaf = 1,\n",
    "            max_features = 'sqrt',\n",
    "            max_depth = 90,\n",
    "            bootstrap = True\n",
    "        )),\n",
    "        ('svc', SVC(\n",
    "            C = 0.1, gamma = 1, kernel = 'rbf'\n",
    "        )), \n",
    "        ('knn', KNeighborsClassifier(\n",
    "            metric = 'minkowski', \n",
    "            n_neighbors = 5, \n",
    "            weights = 'uniform'\n",
    "        )),\n",
    "        ('adb', AdaBoostClassifier(\n",
    "            learning_rate = 0.001,\n",
    "            n_estimators = 50\n",
    "        ))\n",
    "    ], \n",
    "    voting='hard'\n",
    ")\n",
    "# {'learning_rate': 0.001, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
    "vt_model.fit(X_train, y_train)\n",
    "final_predictions = vt_model.predict(transformed_submission_data)\n",
    "# final_predictions = rf_best_model.predict(transformed_submission_data)\n",
    "final_prediction_series = pd.Series(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0375e4cd-fdb0-4b82-8508-6ff022061cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the results into dataframe\n",
    "submission_df = pd.DataFrame({'id':test_file['Latitude and Longitude'].values, 'target':final_prediction_series.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ddcb914e-bc32-4818-86b9-72bd99848111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Rice</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rice</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id\n",
       "target       \n",
       "Non Rice  147\n",
       "Rice      103"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.groupby('target').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "15268aa1-37ad-4b56-a1d7-2d0f837e892a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Rice</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rice</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id\n",
       "target       \n",
       "Non Rice  143\n",
       "Rice      107"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.groupby('target').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2fcec864-4da3-41e7-80da-b77e42a9d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dumping the predictions into a csv file.\n",
    "submission_df.to_csv(\"../../output/submission_sentinel_rtc_1_vh_vv_median_mean_1_year_5x5_voting_classifier.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c2fba-5ecb-4ea5-a4a5-1fd6a74952cc",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10632df0-a001-4932-8ef9-c7dc9023cc7f",
   "metadata": {},
   "source": [
    "Now that you have learned a basic approach to model training, it’s time to try your own approach! Feel free to modify any of the functions presented in this notebook. We look forward to seeing your version of the model and the results. Best of luck with the challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
